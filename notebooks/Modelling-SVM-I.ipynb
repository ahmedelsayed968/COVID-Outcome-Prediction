{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93f15226-db58-47a4-bac6-32a737d992ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src import *\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa3803b7-d50d-4174-8281-511ab8ff1ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "con = sqlite3.connect(\"covid-db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c4b9204-e03c-4f9f-88a4-bff852f45c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"select * from patients\",con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5deb4a54-1895-431f-8055-dde4f85a8041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>vis_wuhan</th>\n",
       "      <th>from_wuhan</th>\n",
       "      <th>symptom1</th>\n",
       "      <th>symptom2</th>\n",
       "      <th>symptom3</th>\n",
       "      <th>symptom4</th>\n",
       "      <th>symptom5</th>\n",
       "      <th>symptom6</th>\n",
       "      <th>diff_sym_hos</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>116</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>49.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>49.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>863 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     location  country  gender   age  vis_wuhan  from_wuhan  symptom1  \\\n",
       "0         104        8       1  66.0          1           0        14   \n",
       "1         101        8       0  56.0          0           1        14   \n",
       "2         137        8       1  46.0          0           1        14   \n",
       "3         116        8       0  60.0          1           0        14   \n",
       "4         116        8       1  58.0          0           0        14   \n",
       "..        ...      ...     ...   ...        ...         ...       ...   \n",
       "858        48        3       2  24.0          0           0        14   \n",
       "859         0        0       2  35.0          0           0        14   \n",
       "860         3        1       1  49.4          0           0        14   \n",
       "861        24        9       1  49.4          0           0        14   \n",
       "862        15       27       1  70.0          0           0        14   \n",
       "\n",
       "     symptom2  symptom3  symptom4  symptom5  symptom6  diff_sym_hos  result  \n",
       "0          31        19        12         3         1             8       1  \n",
       "1          31        19        12         3         1             0       0  \n",
       "2          31        19        12         3         1            13       0  \n",
       "3          31        19        12         3         1             0       0  \n",
       "4          31        19        12         3         1             0       0  \n",
       "..        ...       ...       ...       ...       ...           ...     ...  \n",
       "858        31        19        12         3         1             0       1  \n",
       "859        31        19        12         3         1             0       0  \n",
       "860        31        19        12         3         1             0       0  \n",
       "861        31        19        12         3         1             0       0  \n",
       "862        31        19        12         3         1             0       0  \n",
       "\n",
       "[863 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "be6139c3-8b00-4add-886e-70ea6825a2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train: (690, 13)\n",
      "shape of X_test: (173, 13)\n",
      "shape of y_train: (690,)\n",
      "shape of y_test: (173,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(['result'],axis=1)\n",
    "y = df['result']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2023)\n",
    "print(f\"shape of X_train: {X_train.shape}\")\n",
    "print(f\"shape of X_test: {X_test.shape}\")\n",
    "print(f\"shape of y_train: {y_train.shape}\")\n",
    "print(f\"shape of y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "381ba747-9661-4697-9d4a-5b0e4f54142b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6 11 12]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X_train and y_train are defined\n",
    "\n",
    "# Feature selection using F-test\n",
    "f_test_selector = SelectKBest(score_func=f_classif, k=6)  # Adjust k as needed\n",
    "\n",
    "# Feature selection using Mutual Information\n",
    "mutual_info_selector = SelectKBest(score_func=mutual_info_classif, k=6)  # Adjust k as needed\n",
    "\n",
    "# ColumnTransformer to handle transformations separately on X_train\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('f_test', f_test_selector, X_train.columns),\n",
    "        ('mutual_info', mutual_info_selector, X_train.columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create the final pipeline for feature selection\n",
    "pipeline_feature_selection = Pipeline([\n",
    "    ('preprocessor', preprocessor)\n",
    "])\n",
    "\n",
    "# Fit and transform the data for feature selection\n",
    "X_train_transformed = pipeline_feature_selection.fit_transform(X_train, y_train)\n",
    "X_test_transformed = pipeline_feature_selection.transform(X_test)\n",
    "\n",
    "# Get selected feature indices from both selectors\n",
    "selected_features_f_test = pipeline_feature_selection.named_steps['preprocessor'].named_transformers_['f_test'].get_support(indices=True)\n",
    "selected_features_mutual_info = pipeline_feature_selection.named_steps['preprocessor'].named_transformers_['mutual_info'].get_support(indices=True)\n",
    "\n",
    "# Union of selected features\n",
    "selected_features_union = np.union1d(selected_features_f_test, selected_features_mutual_info)\n",
    "print(selected_features_union)\n",
    "# Transform X_train and X_test based on the selected features union\n",
    "X_train_union = X_train.iloc[:, selected_features_union]\n",
    "X_test_union = X_test.iloc[:, selected_features_union]\n",
    "selected_features_union.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c907281-1a91-481a-92c9-78ec01bb5116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>vis_wuhan</th>\n",
       "      <th>from_wuhan</th>\n",
       "      <th>symptom1</th>\n",
       "      <th>symptom5</th>\n",
       "      <th>diff_sym_hos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>49.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>49.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>108</td>\n",
       "      <td>24</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>99</td>\n",
       "      <td>8</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>45</td>\n",
       "      <td>13</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>45</td>\n",
       "      <td>13</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>108</td>\n",
       "      <td>24</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>114</td>\n",
       "      <td>29</td>\n",
       "      <td>49.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>49.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     location  country   age  vis_wuhan  from_wuhan  symptom1  symptom5  \\\n",
       "560        19       32  49.4          1           0        14         3   \n",
       "161        27       11  49.4          0           0        14         3   \n",
       "443       108       24  29.0          0           0        14         3   \n",
       "234         1       18  65.0          0           0         6         3   \n",
       "150        99        8  48.0          0           0        14         3   \n",
       "..        ...      ...   ...        ...         ...       ...       ...   \n",
       "732        45       13  38.0          0           0        14         3   \n",
       "695        45       13  57.0          0           0        14         3   \n",
       "454       108       24  34.0          0           0        14         3   \n",
       "537       114       29  49.4          1           0        14         3   \n",
       "855        10        4  49.4          0           0        14         3   \n",
       "\n",
       "     diff_sym_hos  \n",
       "560             0  \n",
       "161             0  \n",
       "443             0  \n",
       "234             0  \n",
       "150             2  \n",
       "..            ...  \n",
       "732             0  \n",
       "695             0  \n",
       "454             0  \n",
       "537             0  \n",
       "855             0  \n",
       "\n",
       "[690 rows x 8 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[:,selected_features_union]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "89b5ae91-43fb-495c-b373-3533e2946503",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from umap import UMAP\n",
    "preprocessor = Pipeline([\n",
    "    (\"UMAP\",UMAP(n_components=3,\n",
    "                           init='random',\n",
    "                           random_state=2023,)),\n",
    "    (\"scaling\",StandardScaler())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ea5f7345-0f3a-4132-91cf-3744c9232929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>vis_wuhan</th>\n",
       "      <th>from_wuhan</th>\n",
       "      <th>symptom1</th>\n",
       "      <th>symptom6</th>\n",
       "      <th>diff_sym_hos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>49.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>27</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>49.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>108</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>99</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>45</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>45</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>108</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>114</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>49.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>49.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     location  country  gender   age  vis_wuhan  from_wuhan  symptom1  \\\n",
       "560        19       32       0  49.4          1           0        14   \n",
       "161        27       11       2  49.4          0           0        14   \n",
       "443       108       24       1  29.0          0           0        14   \n",
       "234         1       18       1  65.0          0           0         6   \n",
       "150        99        8       1  48.0          0           0        14   \n",
       "..        ...      ...     ...   ...        ...         ...       ...   \n",
       "732        45       13       0  38.0          0           0        14   \n",
       "695        45       13       0  57.0          0           0        14   \n",
       "454       108       24       0  34.0          0           0        14   \n",
       "537       114       29       2  49.4          1           0        14   \n",
       "855        10        4       0  49.4          0           0        14   \n",
       "\n",
       "     symptom6  diff_sym_hos  \n",
       "560         1             0  \n",
       "161         1             0  \n",
       "443         1             0  \n",
       "234         1             0  \n",
       "150         1             2  \n",
       "..        ...           ...  \n",
       "732         1             0  \n",
       "695         1             0  \n",
       "454         1             0  \n",
       "537         1             0  \n",
       "855         1             0  \n",
       "\n",
       "[690 rows x 9 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "468d8546-2ee7-488d-8637-9d78d54ba507",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\projects\\COVID-Outcome-Prediction\\venv\\Lib\\site-packages\\umap\\umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    }
   ],
   "source": [
    "features = preprocessor.fit_transform(X_train_union,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d0aa2c97-b89e-4fcf-9706-540e3cf436bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.8889172 ,  0.1935595 , -0.5497921 ],\n",
       "       [ 0.6132821 ,  0.36662254, -1.153789  ],\n",
       "       [-0.06468447, -1.0765722 ,  0.60862976],\n",
       "       ...,\n",
       "       [-0.06231092, -1.0454506 ,  0.6963742 ],\n",
       "       [ 0.58701307,  1.6370366 ,  0.5583574 ],\n",
       "       [ 2.3940287 , -4.581596  ,  0.27464002]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25445dce-dc73-4522-ac89-bf906cc2a20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import warnings as warn\n",
    "import pandas as panda_obj\n",
    "from sklearn.model_selection import train_test_split as tts, ParameterGrid as pg, GridSearchCV as gscv\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score as acs, classification_report as cr\n",
    "os.environ[\"GIT_PYTHON_REFRESH\"] = \"quiet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "048c7bca-6e04-4cad-8d63-cc549918d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c404139-c0d1-4009-b55c-83aefbb8a05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/12/14 11:15:55 INFO mlflow.tracking.fluent: Experiment with name 'Union-Features-FTest-Mutual' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/542480374940682006', creation_time=1702545355793, experiment_id='542480374940682006', last_update_time=1702545355793, lifecycle_stage='active', name='Union-Features-FTest-Mutual', tags={}>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adm_experiment_name = \"Union-Features-FTest-Mutual\"\n",
    "mlflow.set_experiment(adm_experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aab62b12-3997-4853-9551-e604bc7bea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train==0] = -1\n",
    "y_train[y_train==1] = 1\n",
    "y_test[y_test==0] = -1\n",
    "y_test[y_test==1] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f696db3d-dc61-41e0-8529-7612674a04e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1], dtype=int64)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f5c43d93-4fb9-43eb-8116-161a381f2eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560   -1\n",
       "161   -1\n",
       "443   -1\n",
       "234   -1\n",
       "150   -1\n",
       "      ..\n",
       "732   -1\n",
       "695   -1\n",
       "454   -1\n",
       "537   -1\n",
       "855   -1\n",
       "Name: result, Length: 690, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "769de67f-8bfa-4f6c-b1a6-93517784842c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\projects\\COVID-Outcome-Prediction\\venv\\Lib\\site-packages\\umap\\umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 1.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 1.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 1.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 2.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 2.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 2.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8554913294797688\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.89      0.94      0.91       141\n",
      "           1       0.64      0.50      0.56        32\n",
      "\n",
      "    accuracy                           0.86       173\n",
      "   macro avg       0.77      0.72      0.74       173\n",
      "weighted avg       0.85      0.86      0.85       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 3.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 3.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.838150289017341\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.96      0.91       141\n",
      "           1       0.64      0.28      0.39        32\n",
      "\n",
      "    accuracy                           0.84       173\n",
      "   macro avg       0.75      0.62      0.65       173\n",
      "weighted avg       0.82      0.84      0.81       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 3.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8901734104046243\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.91      0.93       141\n",
      "           1       0.68      0.78      0.72        32\n",
      "\n",
      "    accuracy                           0.89       173\n",
      "   macro avg       0.81      0.85      0.83       173\n",
      "weighted avg       0.90      0.89      0.89       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 4.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 4.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.7861271676300579\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.87      0.87       141\n",
      "           1       0.42      0.41      0.41        32\n",
      "\n",
      "    accuracy                           0.79       173\n",
      "   macro avg       0.64      0.64      0.64       173\n",
      "weighted avg       0.78      0.79      0.78       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 4.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8786127167630058\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.89      0.92       141\n",
      "           1       0.63      0.81      0.71        32\n",
      "\n",
      "    accuracy                           0.88       173\n",
      "   macro avg       0.79      0.85      0.82       173\n",
      "weighted avg       0.90      0.88      0.88       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 5.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 5.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.7572254335260116\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.82      0.85       141\n",
      "           1       0.38      0.47      0.42        32\n",
      "\n",
      "    accuracy                           0.76       173\n",
      "   macro avg       0.62      0.65      0.63       173\n",
      "weighted avg       0.78      0.76      0.77       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 5.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.861271676300578\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.87      0.91       141\n",
      "           1       0.59      0.81      0.68        32\n",
      "\n",
      "    accuracy                           0.86       173\n",
      "   macro avg       0.77      0.84      0.80       173\n",
      "weighted avg       0.89      0.86      0.87       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 6.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 6.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.7052023121387283\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.66      0.78       141\n",
      "           1       0.38      0.91      0.53        32\n",
      "\n",
      "    accuracy                           0.71       173\n",
      "   macro avg       0.67      0.78      0.66       173\n",
      "weighted avg       0.86      0.71      0.74       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 6.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.838150289017341\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.84      0.89       141\n",
      "           1       0.54      0.81      0.65        32\n",
      "\n",
      "    accuracy                           0.84       173\n",
      "   macro avg       0.75      0.83      0.77       173\n",
      "weighted avg       0.88      0.84      0.85       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 7.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 7.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.6589595375722543\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      0.60      0.74       141\n",
      "           1       0.34      0.94      0.50        32\n",
      "\n",
      "    accuracy                           0.66       173\n",
      "   macro avg       0.66      0.77      0.62       173\n",
      "weighted avg       0.86      0.66      0.70       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 7.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8323699421965318\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.84      0.89       141\n",
      "           1       0.53      0.81      0.64        32\n",
      "\n",
      "    accuracy                           0.83       173\n",
      "   macro avg       0.74      0.82      0.77       173\n",
      "weighted avg       0.87      0.83      0.84       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 8.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.4393063583815029\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.40      0.54       141\n",
      "           1       0.18      0.59      0.28        32\n",
      "\n",
      "    accuracy                           0.44       173\n",
      "   macro avg       0.50      0.50      0.41       173\n",
      "weighted avg       0.70      0.44      0.49       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 8.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.6473988439306358\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      0.58      0.73       141\n",
      "           1       0.34      0.94      0.50        32\n",
      "\n",
      "    accuracy                           0.65       173\n",
      "   macro avg       0.66      0.76      0.61       173\n",
      "weighted avg       0.86      0.65      0.69       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 8.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8323699421965318\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.84      0.89       141\n",
      "           1       0.53      0.81      0.64        32\n",
      "\n",
      "    accuracy                           0.83       173\n",
      "   macro avg       0.74      0.82      0.77       173\n",
      "weighted avg       0.87      0.83      0.84       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 9.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.4161849710982659\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.28      0.44       141\n",
      "           1       0.24      1.00      0.39        32\n",
      "\n",
      "    accuracy                           0.42       173\n",
      "   macro avg       0.62      0.64      0.41       173\n",
      "weighted avg       0.86      0.42      0.43       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 9.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.6416184971098265\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      0.57      0.72       141\n",
      "           1       0.33      0.94      0.49        32\n",
      "\n",
      "    accuracy                           0.64       173\n",
      "   macro avg       0.65      0.76      0.61       173\n",
      "weighted avg       0.86      0.64      0.68       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 9.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8323699421965318\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.83      0.89       141\n",
      "           1       0.53      0.84      0.65        32\n",
      "\n",
      "    accuracy                           0.83       173\n",
      "   macro avg       0.74      0.84      0.77       173\n",
      "weighted avg       0.88      0.83      0.85       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 10.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.2023121387283237\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.02      0.04       141\n",
      "           1       0.19      1.00      0.32        32\n",
      "\n",
      "    accuracy                           0.20       173\n",
      "   macro avg       0.59      0.51      0.18       173\n",
      "weighted avg       0.85      0.20      0.09       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 10.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.6416184971098265\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.98      0.57      0.72       141\n",
      "           1       0.33      0.94      0.49        32\n",
      "\n",
      "    accuracy                           0.64       173\n",
      "   macro avg       0.65      0.76      0.61       173\n",
      "weighted avg       0.86      0.64      0.68       173\n",
      "\n",
      "Hyperparameters: {'C': [1], 'class_weight': [{-1: 1.0, 1: 10.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.81      0.88       141\n",
      "           1       0.50      0.84      0.63        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.73      0.83      0.75       173\n",
      "weighted avg       0.87      0.82      0.83       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 1.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 1.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 1.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.838150289017341\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.96      0.91       141\n",
      "           1       0.64      0.28      0.39        32\n",
      "\n",
      "    accuracy                           0.84       173\n",
      "   macro avg       0.75      0.62      0.65       173\n",
      "weighted avg       0.82      0.84      0.81       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 2.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 2.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.838150289017341\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.96      0.91       141\n",
      "           1       0.64      0.28      0.39        32\n",
      "\n",
      "    accuracy                           0.84       173\n",
      "   macro avg       0.75      0.62      0.65       173\n",
      "weighted avg       0.82      0.84      0.81       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 2.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.9017341040462428\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.93      0.94       141\n",
      "           1       0.71      0.78      0.75        32\n",
      "\n",
      "    accuracy                           0.90       173\n",
      "   macro avg       0.83      0.86      0.84       173\n",
      "weighted avg       0.91      0.90      0.90       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 3.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 3.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.8034682080924855\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.90      0.88       141\n",
      "           1       0.46      0.38      0.41        32\n",
      "\n",
      "    accuracy                           0.80       173\n",
      "   macro avg       0.66      0.64      0.65       173\n",
      "weighted avg       0.79      0.80      0.80       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 3.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8901734104046243\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.91      0.93       141\n",
      "           1       0.68      0.78      0.72        32\n",
      "\n",
      "    accuracy                           0.89       173\n",
      "   macro avg       0.81      0.85      0.83       173\n",
      "weighted avg       0.90      0.89      0.89       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 4.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 4.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.7745664739884393\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.87      0.86       141\n",
      "           1       0.39      0.38      0.38        32\n",
      "\n",
      "    accuracy                           0.77       173\n",
      "   macro avg       0.62      0.62      0.62       173\n",
      "weighted avg       0.77      0.77      0.77       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 4.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8728323699421965\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.89      0.92       141\n",
      "           1       0.62      0.78      0.69        32\n",
      "\n",
      "    accuracy                           0.87       173\n",
      "   macro avg       0.79      0.84      0.81       173\n",
      "weighted avg       0.89      0.87      0.88       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 5.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 5.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.7225433526011561\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.69      0.80       141\n",
      "           1       0.39      0.88      0.54        32\n",
      "\n",
      "    accuracy                           0.72       173\n",
      "   macro avg       0.67      0.78      0.67       173\n",
      "weighted avg       0.85      0.72      0.75       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 5.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.861271676300578\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.88      0.91       141\n",
      "           1       0.60      0.78      0.68        32\n",
      "\n",
      "    accuracy                           0.86       173\n",
      "   macro avg       0.77      0.83      0.79       173\n",
      "weighted avg       0.88      0.86      0.87       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 6.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 6.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.6936416184971098\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.65      0.78       141\n",
      "           1       0.36      0.88      0.51        32\n",
      "\n",
      "    accuracy                           0.69       173\n",
      "   macro avg       0.66      0.76      0.65       173\n",
      "weighted avg       0.85      0.69      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 6.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8670520231213873\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.88      0.92       141\n",
      "           1       0.60      0.81      0.69        32\n",
      "\n",
      "    accuracy                           0.87       173\n",
      "   macro avg       0.78      0.85      0.80       173\n",
      "weighted avg       0.89      0.87      0.87       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 7.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 7.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.6878612716763006\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.65      0.77       141\n",
      "           1       0.36      0.88      0.51        32\n",
      "\n",
      "    accuracy                           0.69       173\n",
      "   macro avg       0.66      0.76      0.64       173\n",
      "weighted avg       0.85      0.69      0.72       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 7.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8670520231213873\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.88      0.92       141\n",
      "           1       0.60      0.81      0.69        32\n",
      "\n",
      "    accuracy                           0.87       173\n",
      "   macro avg       0.78      0.85      0.80       173\n",
      "weighted avg       0.89      0.87      0.87       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 8.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.4393063583815029\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.40      0.54       141\n",
      "           1       0.18      0.59      0.28        32\n",
      "\n",
      "    accuracy                           0.44       173\n",
      "   macro avg       0.50      0.50      0.41       173\n",
      "weighted avg       0.70      0.44      0.49       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 8.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.6878612716763006\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.65      0.77       141\n",
      "           1       0.36      0.88      0.51        32\n",
      "\n",
      "    accuracy                           0.69       173\n",
      "   macro avg       0.66      0.76      0.64       173\n",
      "weighted avg       0.85      0.69      0.72       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 8.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.861271676300578\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.87      0.91       141\n",
      "           1       0.59      0.81      0.68        32\n",
      "\n",
      "    accuracy                           0.86       173\n",
      "   macro avg       0.77      0.84      0.80       173\n",
      "weighted avg       0.89      0.86      0.87       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 9.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.4277456647398844\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.30      0.46       141\n",
      "           1       0.24      1.00      0.39        32\n",
      "\n",
      "    accuracy                           0.43       173\n",
      "   macro avg       0.62      0.65      0.43       173\n",
      "weighted avg       0.86      0.43      0.45       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 9.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.6820809248554913\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.63      0.76       141\n",
      "           1       0.36      0.91      0.51        32\n",
      "\n",
      "    accuracy                           0.68       173\n",
      "   macro avg       0.66      0.77      0.64       173\n",
      "weighted avg       0.85      0.68      0.72       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 9.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8439306358381503\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.85      0.90       141\n",
      "           1       0.55      0.81      0.66        32\n",
      "\n",
      "    accuracy                           0.84       173\n",
      "   macro avg       0.75      0.83      0.78       173\n",
      "weighted avg       0.88      0.84      0.85       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 10.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.2023121387283237\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.02      0.04       141\n",
      "           1       0.19      1.00      0.32        32\n",
      "\n",
      "    accuracy                           0.20       173\n",
      "   macro avg       0.59      0.51      0.18       173\n",
      "weighted avg       0.85      0.20      0.09       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 10.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.6936416184971098\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.65      0.77       141\n",
      "           1       0.37      0.91      0.52        32\n",
      "\n",
      "    accuracy                           0.69       173\n",
      "   macro avg       0.67      0.78      0.65       173\n",
      "weighted avg       0.86      0.69      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [5], 'class_weight': [{-1: 1.0, 1: 10.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8439306358381503\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.85      0.90       141\n",
      "           1       0.55      0.81      0.66        32\n",
      "\n",
      "    accuracy                           0.84       173\n",
      "   macro avg       0.75      0.83      0.78       173\n",
      "weighted avg       0.88      0.84      0.85       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 1.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 1.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 1.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.838150289017341\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.96      0.91       141\n",
      "           1       0.64      0.28      0.39        32\n",
      "\n",
      "    accuracy                           0.84       173\n",
      "   macro avg       0.75      0.62      0.65       173\n",
      "weighted avg       0.82      0.84      0.81       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 2.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 2.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.8208092485549133\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.94      0.90       141\n",
      "           1       0.53      0.28      0.37        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.69      0.61      0.63       173\n",
      "weighted avg       0.79      0.82      0.80       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 2.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.9017341040462428\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.93      0.94       141\n",
      "           1       0.71      0.78      0.75        32\n",
      "\n",
      "    accuracy                           0.90       173\n",
      "   macro avg       0.83      0.86      0.84       173\n",
      "weighted avg       0.91      0.90      0.90       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 3.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 3.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.791907514450867\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.86      0.89      0.87       141\n",
      "           1       0.43      0.38      0.40        32\n",
      "\n",
      "    accuracy                           0.79       173\n",
      "   macro avg       0.65      0.63      0.64       173\n",
      "weighted avg       0.78      0.79      0.79       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 3.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8901734104046243\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.91      0.93       141\n",
      "           1       0.68      0.78      0.72        32\n",
      "\n",
      "    accuracy                           0.89       173\n",
      "   macro avg       0.81      0.85      0.83       173\n",
      "weighted avg       0.90      0.89      0.89       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 4.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 4.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.7976878612716763\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.90      0.84      0.87       141\n",
      "           1       0.46      0.59      0.52        32\n",
      "\n",
      "    accuracy                           0.80       173\n",
      "   macro avg       0.68      0.72      0.70       173\n",
      "weighted avg       0.82      0.80      0.81       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 4.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8670520231213873\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.89      0.92       141\n",
      "           1       0.61      0.78      0.68        32\n",
      "\n",
      "    accuracy                           0.87       173\n",
      "   macro avg       0.78      0.83      0.80       173\n",
      "weighted avg       0.88      0.87      0.87       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 5.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 5.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.7283236994219653\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.71      0.81       141\n",
      "           1       0.39      0.81      0.53        32\n",
      "\n",
      "    accuracy                           0.73       173\n",
      "   macro avg       0.67      0.76      0.67       173\n",
      "weighted avg       0.84      0.73      0.76       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 5.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8728323699421965\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.89      0.92       141\n",
      "           1       0.62      0.81      0.70        32\n",
      "\n",
      "    accuracy                           0.87       173\n",
      "   macro avg       0.79      0.85      0.81       173\n",
      "weighted avg       0.89      0.87      0.88       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 6.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 6.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.6936416184971098\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.66      0.78       141\n",
      "           1       0.36      0.84      0.50        32\n",
      "\n",
      "    accuracy                           0.69       173\n",
      "   macro avg       0.65      0.75      0.64       173\n",
      "weighted avg       0.84      0.69      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 6.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8728323699421965\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.89      0.92       141\n",
      "           1       0.62      0.81      0.70        32\n",
      "\n",
      "    accuracy                           0.87       173\n",
      "   macro avg       0.79      0.85      0.81       173\n",
      "weighted avg       0.89      0.87      0.88       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 7.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 7.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.6936416184971098\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.65      0.78       141\n",
      "           1       0.36      0.88      0.51        32\n",
      "\n",
      "    accuracy                           0.69       173\n",
      "   macro avg       0.66      0.76      0.65       173\n",
      "weighted avg       0.85      0.69      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 7.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8554913294797688\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.87      0.91       141\n",
      "           1       0.58      0.81      0.68        32\n",
      "\n",
      "    accuracy                           0.86       173\n",
      "   macro avg       0.77      0.84      0.79       173\n",
      "weighted avg       0.88      0.86      0.86       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 8.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.4393063583815029\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.40      0.54       141\n",
      "           1       0.18      0.59      0.28        32\n",
      "\n",
      "    accuracy                           0.44       173\n",
      "   macro avg       0.50      0.50      0.41       173\n",
      "weighted avg       0.70      0.44      0.49       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 8.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.6936416184971098\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.65      0.78       141\n",
      "           1       0.36      0.88      0.51        32\n",
      "\n",
      "    accuracy                           0.69       173\n",
      "   macro avg       0.66      0.76      0.65       173\n",
      "weighted avg       0.85      0.69      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 8.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8497109826589595\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.86      0.90       141\n",
      "           1       0.57      0.81      0.67        32\n",
      "\n",
      "    accuracy                           0.85       173\n",
      "   macro avg       0.76      0.84      0.78       173\n",
      "weighted avg       0.88      0.85      0.86       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 9.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.4277456647398844\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.30      0.46       141\n",
      "           1       0.24      1.00      0.39        32\n",
      "\n",
      "    accuracy                           0.43       173\n",
      "   macro avg       0.62      0.65      0.43       173\n",
      "weighted avg       0.86      0.43      0.45       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 9.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.6936416184971098\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.65      0.78       141\n",
      "           1       0.36      0.88      0.51        32\n",
      "\n",
      "    accuracy                           0.69       173\n",
      "   macro avg       0.66      0.76      0.65       173\n",
      "weighted avg       0.85      0.69      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 9.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8497109826589595\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.86      0.90       141\n",
      "           1       0.57      0.81      0.67        32\n",
      "\n",
      "    accuracy                           0.85       173\n",
      "   macro avg       0.76      0.84      0.78       173\n",
      "weighted avg       0.88      0.85      0.86       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 10.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.2023121387283237\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.02      0.04       141\n",
      "           1       0.19      1.00      0.32        32\n",
      "\n",
      "    accuracy                           0.20       173\n",
      "   macro avg       0.59      0.51      0.18       173\n",
      "weighted avg       0.85      0.20      0.09       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 10.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.6936416184971098\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.97      0.65      0.77       141\n",
      "           1       0.37      0.91      0.52        32\n",
      "\n",
      "    accuracy                           0.69       173\n",
      "   macro avg       0.67      0.78      0.65       173\n",
      "weighted avg       0.86      0.69      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [10], 'class_weight': [{-1: 1.0, 1: 10.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8439306358381503\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.85      0.90       141\n",
      "           1       0.55      0.81      0.66        32\n",
      "\n",
      "    accuracy                           0.84       173\n",
      "   macro avg       0.75      0.83      0.78       173\n",
      "weighted avg       0.88      0.84      0.85       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 1.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 1.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 1.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8439306358381503\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.95      0.91       141\n",
      "           1       0.63      0.38      0.47        32\n",
      "\n",
      "    accuracy                           0.84       173\n",
      "   macro avg       0.75      0.66      0.69       173\n",
      "weighted avg       0.83      0.84      0.83       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 2.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 2.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.8034682080924855\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.92      0.88       141\n",
      "           1       0.45      0.28      0.35        32\n",
      "\n",
      "    accuracy                           0.80       173\n",
      "   macro avg       0.65      0.60      0.62       173\n",
      "weighted avg       0.78      0.80      0.78       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 2.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.9017341040462428\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.93      0.94       141\n",
      "           1       0.71      0.78      0.75        32\n",
      "\n",
      "    accuracy                           0.90       173\n",
      "   macro avg       0.83      0.86      0.84       173\n",
      "weighted avg       0.91      0.90      0.90       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 3.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 3.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.7861271676300579\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.87      0.87       141\n",
      "           1       0.42      0.41      0.41        32\n",
      "\n",
      "    accuracy                           0.79       173\n",
      "   macro avg       0.64      0.64      0.64       173\n",
      "weighted avg       0.78      0.79      0.78       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 3.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8728323699421965\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.89      0.92       141\n",
      "           1       0.62      0.78      0.69        32\n",
      "\n",
      "    accuracy                           0.87       173\n",
      "   macro avg       0.79      0.84      0.81       173\n",
      "weighted avg       0.89      0.87      0.88       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 4.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 4.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.791907514450867\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      0.80      0.86       141\n",
      "           1       0.46      0.75      0.57        32\n",
      "\n",
      "    accuracy                           0.79       173\n",
      "   macro avg       0.70      0.78      0.72       173\n",
      "weighted avg       0.85      0.79      0.81       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 4.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8728323699421965\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.89      0.92       141\n",
      "           1       0.62      0.81      0.70        32\n",
      "\n",
      "    accuracy                           0.87       173\n",
      "   macro avg       0.79      0.85      0.81       173\n",
      "weighted avg       0.89      0.87      0.88       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 5.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 5.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.7687861271676301\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.75      0.84       141\n",
      "           1       0.44      0.84      0.57        32\n",
      "\n",
      "    accuracy                           0.77       173\n",
      "   macro avg       0.70      0.80      0.71       173\n",
      "weighted avg       0.86      0.77      0.79       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 5.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.861271676300578\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.87      0.91       141\n",
      "           1       0.59      0.81      0.68        32\n",
      "\n",
      "    accuracy                           0.86       173\n",
      "   macro avg       0.77      0.84      0.80       173\n",
      "weighted avg       0.89      0.86      0.87       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 6.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 6.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.7398843930635838\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.72      0.82       141\n",
      "           1       0.40      0.84      0.55        32\n",
      "\n",
      "    accuracy                           0.74       173\n",
      "   macro avg       0.68      0.78      0.68       173\n",
      "weighted avg       0.85      0.74      0.77       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 6.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8554913294797688\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.87      0.91       141\n",
      "           1       0.58      0.81      0.68        32\n",
      "\n",
      "    accuracy                           0.86       173\n",
      "   macro avg       0.77      0.84      0.79       173\n",
      "weighted avg       0.88      0.86      0.86       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 7.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 7.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.7167630057803468\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.69      0.80       141\n",
      "           1       0.38      0.84      0.52        32\n",
      "\n",
      "    accuracy                           0.72       173\n",
      "   macro avg       0.67      0.77      0.66       173\n",
      "weighted avg       0.85      0.72      0.75       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 7.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8554913294797688\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.87      0.91       141\n",
      "           1       0.58      0.81      0.68        32\n",
      "\n",
      "    accuracy                           0.86       173\n",
      "   macro avg       0.77      0.84      0.79       173\n",
      "weighted avg       0.88      0.86      0.86       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 8.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.4393063583815029\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.40      0.54       141\n",
      "           1       0.18      0.59      0.28        32\n",
      "\n",
      "    accuracy                           0.44       173\n",
      "   macro avg       0.50      0.50      0.41       173\n",
      "weighted avg       0.70      0.44      0.49       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 8.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.7052023121387283\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.67      0.79       141\n",
      "           1       0.37      0.84      0.51        32\n",
      "\n",
      "    accuracy                           0.71       173\n",
      "   macro avg       0.66      0.76      0.65       173\n",
      "weighted avg       0.84      0.71      0.74       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 8.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8554913294797688\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.87      0.91       141\n",
      "           1       0.58      0.81      0.68        32\n",
      "\n",
      "    accuracy                           0.86       173\n",
      "   macro avg       0.77      0.84      0.79       173\n",
      "weighted avg       0.88      0.86      0.86       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 9.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.4277456647398844\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.30      0.46       141\n",
      "           1       0.24      1.00      0.39        32\n",
      "\n",
      "    accuracy                           0.43       173\n",
      "   macro avg       0.62      0.65      0.43       173\n",
      "weighted avg       0.86      0.43      0.45       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 9.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.7052023121387283\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.67      0.79       141\n",
      "           1       0.37      0.84      0.51        32\n",
      "\n",
      "    accuracy                           0.71       173\n",
      "   macro avg       0.66      0.76      0.65       173\n",
      "weighted avg       0.84      0.71      0.74       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 9.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8497109826589595\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.86      0.90       141\n",
      "           1       0.57      0.81      0.67        32\n",
      "\n",
      "    accuracy                           0.85       173\n",
      "   macro avg       0.76      0.84      0.78       173\n",
      "weighted avg       0.88      0.85      0.86       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 10.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.2023121387283237\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.02      0.04       141\n",
      "           1       0.19      1.00      0.32        32\n",
      "\n",
      "    accuracy                           0.20       173\n",
      "   macro avg       0.59      0.51      0.18       173\n",
      "weighted avg       0.85      0.20      0.09       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 10.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.7109826589595376\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.67      0.79       141\n",
      "           1       0.38      0.88      0.53        32\n",
      "\n",
      "    accuracy                           0.71       173\n",
      "   macro avg       0.67      0.77      0.66       173\n",
      "weighted avg       0.85      0.71      0.74       173\n",
      "\n",
      "Hyperparameters: {'C': [25], 'class_weight': [{-1: 1.0, 1: 10.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8554913294797688\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.86      0.91       141\n",
      "           1       0.57      0.84      0.68        32\n",
      "\n",
      "    accuracy                           0.86       173\n",
      "   macro avg       0.77      0.85      0.79       173\n",
      "weighted avg       0.89      0.86      0.87       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 1.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 1.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 1.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8959537572254336\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.92      0.96      0.94       141\n",
      "           1       0.77      0.62      0.69        32\n",
      "\n",
      "    accuracy                           0.90       173\n",
      "   macro avg       0.84      0.79      0.81       173\n",
      "weighted avg       0.89      0.90      0.89       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 2.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 2.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.8092485549132948\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.85      0.93      0.89       141\n",
      "           1       0.47      0.28      0.35        32\n",
      "\n",
      "    accuracy                           0.81       173\n",
      "   macro avg       0.66      0.61      0.62       173\n",
      "weighted avg       0.78      0.81      0.79       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 2.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8959537572254336\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.93      0.94       141\n",
      "           1       0.71      0.75      0.73        32\n",
      "\n",
      "    accuracy                           0.90       173\n",
      "   macro avg       0.82      0.84      0.83       173\n",
      "weighted avg       0.90      0.90      0.90       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 3.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 3.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.7861271676300579\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.87      0.87      0.87       141\n",
      "           1       0.42      0.41      0.41        32\n",
      "\n",
      "    accuracy                           0.79       173\n",
      "   macro avg       0.64      0.64      0.64       173\n",
      "weighted avg       0.78      0.79      0.78       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 3.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8670520231213873\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.89      0.92       141\n",
      "           1       0.61      0.78      0.68        32\n",
      "\n",
      "    accuracy                           0.87       173\n",
      "   macro avg       0.78      0.83      0.80       173\n",
      "weighted avg       0.88      0.87      0.87       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 4.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 4.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.8034682080924855\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.94      0.81      0.87       141\n",
      "           1       0.48      0.78      0.60        32\n",
      "\n",
      "    accuracy                           0.80       173\n",
      "   macro avg       0.71      0.79      0.73       173\n",
      "weighted avg       0.86      0.80      0.82       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 4.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8728323699421965\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.89      0.92       141\n",
      "           1       0.62      0.81      0.70        32\n",
      "\n",
      "    accuracy                           0.87       173\n",
      "   macro avg       0.79      0.85      0.81       173\n",
      "weighted avg       0.89      0.87      0.88       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 5.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 5.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.8034682080924855\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.80      0.87       141\n",
      "           1       0.48      0.81      0.60        32\n",
      "\n",
      "    accuracy                           0.80       173\n",
      "   macro avg       0.72      0.81      0.74       173\n",
      "weighted avg       0.86      0.80      0.82       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 5.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.861271676300578\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.87      0.91       141\n",
      "           1       0.59      0.81      0.68        32\n",
      "\n",
      "    accuracy                           0.86       173\n",
      "   macro avg       0.77      0.84      0.80       173\n",
      "weighted avg       0.89      0.86      0.87       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 6.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 6.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.7398843930635838\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.72      0.82       141\n",
      "           1       0.40      0.84      0.55        32\n",
      "\n",
      "    accuracy                           0.74       173\n",
      "   macro avg       0.68      0.78      0.68       173\n",
      "weighted avg       0.85      0.74      0.77       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 6.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8554913294797688\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.87      0.91       141\n",
      "           1       0.58      0.81      0.68        32\n",
      "\n",
      "    accuracy                           0.86       173\n",
      "   macro avg       0.77      0.84      0.79       173\n",
      "weighted avg       0.88      0.86      0.86       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 7.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      1.00      0.90       141\n",
      "           1       1.00      0.00      0.00        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.91      0.50      0.45       173\n",
      "weighted avg       0.85      0.82      0.73       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 7.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.7167630057803468\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.69      0.80       141\n",
      "           1       0.38      0.84      0.52        32\n",
      "\n",
      "    accuracy                           0.72       173\n",
      "   macro avg       0.67      0.77      0.66       173\n",
      "weighted avg       0.85      0.72      0.75       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 7.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8497109826589595\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.86      0.90       141\n",
      "           1       0.57      0.81      0.67        32\n",
      "\n",
      "    accuracy                           0.85       173\n",
      "   macro avg       0.76      0.84      0.78       173\n",
      "weighted avg       0.88      0.85      0.86       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 8.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.4393063583815029\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.81      0.40      0.54       141\n",
      "           1       0.18      0.59      0.28        32\n",
      "\n",
      "    accuracy                           0.44       173\n",
      "   macro avg       0.50      0.50      0.41       173\n",
      "weighted avg       0.70      0.44      0.49       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 8.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.7109826589595376\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.68      0.79       141\n",
      "           1       0.38      0.84      0.52        32\n",
      "\n",
      "    accuracy                           0.71       173\n",
      "   macro avg       0.66      0.76      0.66       173\n",
      "weighted avg       0.84      0.71      0.74       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 8.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8497109826589595\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.86      0.90       141\n",
      "           1       0.57      0.81      0.67        32\n",
      "\n",
      "    accuracy                           0.85       173\n",
      "   macro avg       0.76      0.84      0.78       173\n",
      "weighted avg       0.88      0.85      0.86       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 9.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.4277456647398844\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.30      0.46       141\n",
      "           1       0.24      1.00      0.39        32\n",
      "\n",
      "    accuracy                           0.43       173\n",
      "   macro avg       0.62      0.65      0.43       173\n",
      "weighted avg       0.86      0.43      0.45       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 9.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.7052023121387283\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.67      0.79       141\n",
      "           1       0.37      0.84      0.51        32\n",
      "\n",
      "    accuracy                           0.71       173\n",
      "   macro avg       0.66      0.76      0.65       173\n",
      "weighted avg       0.84      0.71      0.74       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 9.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.8554913294797688\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.86      0.91       141\n",
      "           1       0.57      0.84      0.68        32\n",
      "\n",
      "    accuracy                           0.86       173\n",
      "   macro avg       0.77      0.85      0.79       173\n",
      "weighted avg       0.89      0.86      0.87       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 10.0}], 'kernel': ['linear']}\n",
      "Accuracy: 0.2023121387283237\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.02      0.04       141\n",
      "           1       0.19      1.00      0.32        32\n",
      "\n",
      "    accuracy                           0.20       173\n",
      "   macro avg       0.59      0.51      0.18       173\n",
      "weighted avg       0.85      0.20      0.09       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 10.0}], 'kernel': ['poly']}\n",
      "Accuracy: 0.7052023121387283\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.67      0.79       141\n",
      "           1       0.37      0.84      0.51        32\n",
      "\n",
      "    accuracy                           0.71       173\n",
      "   macro avg       0.66      0.76      0.65       173\n",
      "weighted avg       0.84      0.71      0.74       173\n",
      "\n",
      "Hyperparameters: {'C': [50], 'class_weight': [{-1: 1.0, 1: 10.0}], 'kernel': ['rbf']}\n",
      "Accuracy: 0.815028901734104\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.96      0.81      0.88       141\n",
      "           1       0.50      0.84      0.63        32\n",
      "\n",
      "    accuracy                           0.82       173\n",
      "   macro avg       0.73      0.83      0.75       173\n",
      "weighted avg       0.87      0.82      0.83       173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "svc_obj = SVC(random_state=2023)\n",
    "param_grid = {\n",
    "    'C' : [1, 5, 10,25,50],\n",
    "    'kernel': ['linear', 'poly', 'rbf'],\n",
    "    'class_weight':[{-1: 1.0, 1: weight} for weight in np.linspace(1, 10, 10)]\n",
    "    \n",
    "}\n",
    "features_train = preprocessor.fit_transform(X_train_union,y_train)\n",
    "features_test = preprocessor.transform(X_test_union)\n",
    "with warn.catch_warnings():\n",
    "    warn.filterwarnings(\"ignore\", category=UserWarning, module='.*distutils.*')\n",
    "    for params in pg(param_grid):\n",
    "        with mlflow.start_run(run_name=\"Union-Features-FTest-Mutual Run\"):\n",
    "            # Convert single values to lists\n",
    "            params = {key: [value] if not isinstance(value, list) else value for key, value in params.items()}\n",
    "            mlflow.log_params(params)\n",
    "            grid_search = gscv(svc_obj, param_grid=params, cv=5)\n",
    "            grid_search.fit(features_train, y_train)\n",
    "            std_best_model = grid_search.best_estimator_\n",
    "            \n",
    "            model_predictions = std_best_model.predict(features_test)\n",
    "            model_accuracy_score = acs(y_test,model_predictions)\n",
    "            model_f1_score = f1_score(y_test,model_predictions)\n",
    "            fpr, tpr, _ = roc_curve(y_test, model_predictions)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            print(\"Hyperparameters:\", params)\n",
    "            print(\"Accuracy:\", model_accuracy_score)\n",
    "            # Explicitly ignore the UndefinedMetricWarning\n",
    "            with warn.catch_warnings():\n",
    "                warn.filterwarnings(\"ignore\", category=Warning)\n",
    "                print(\"Classification Report:\")\n",
    "                print(cr(y_test, model_predictions, zero_division=1))\n",
    "            mlflow.log_metric(\"accuracy\", model_accuracy_score)\n",
    "            mlflow.log_metric(\"f1-score\",model_f1_score)\n",
    "            mlflow.log_metric(\"roc-auc\",roc_auc)\n",
    "            mlflow.sklearn.log_model(std_best_model, \"gb_classifier_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2bef4e5a-15d4-421c-84e8-e05fb1d90b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c06d37f05a489b9f5fb762b494f803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import mlflow\n",
    "logged_model = 'runs:/62a0fba0f43146cbb17428351884e9af/gb_classifier_model'\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4999280a-4244-437f-85f5-5a2a33e27d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.95      0.93      0.94       141\n",
      "           1       0.71      0.78      0.75        32\n",
      "\n",
      "    accuracy                           0.90       173\n",
      "   macro avg       0.83      0.86      0.84       173\n",
      "weighted avg       0.91      0.90      0.90       173\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "model_predictions = loaded_model.predict(features_test)\n",
    "model_accuracy_score = acs(y_test,model_predictions)\n",
    "model_f1_score = f1_score(y_test,model_predictions)\n",
    "print(cr(y_test, model_predictions, zero_division=1))\n",
    "fpr, tpr, _ = roc_curve(y_test, model_predictions)\n",
    "plt.plot(fpr, tpr, lw=2)\n",
    "plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', label='Random Classifier')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "734ca7dd-5192-4f09-859b-8afcab4c75c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9202898550724637"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs(y_train,loaded_model.predict(features_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8e728517-ff6d-4502-a8ae-ab1be5b30bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9017341040462428"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25a9d39-994c-477b-950c-da5b3cb77422",
   "metadata": {},
   "source": [
    "- No overfitting\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7f343c-251f-4375-98cf-45366c44c8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
